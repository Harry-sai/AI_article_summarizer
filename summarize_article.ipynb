{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d16401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from scraper import  fetch_website_contents\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc94b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    MODEL = 'gpt-5-nano'\n",
    "    openai = OpenAI()\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "    ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "    MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9de560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleSummarizer:\n",
    "    def __init__(self,Article, url):\n",
    "        self.Article = Article\n",
    "        self.url = url\n",
    "\n",
    "    def fetch_page_and_all_relevant_links(self, url):\n",
    "        contents = fetch_website_contents(url)\n",
    "        result = f\"## Landing Page:\\n\\n{contents}\\n## Relevant Links:\\n\"\n",
    "\n",
    "        return result\n",
    "\n",
    "    summarizer_system_prompt = \"\"\"\n",
    "    When I provide you with a URL to a research article from any academic source \n",
    "    (such as PubMed, arXiv, Elsevier, PNAS, Nature, Science, IEEE, Springer, Wiley, BMC, MDPI, or any other scholarly database), \n",
    "    please follow these steps:\n",
    "\n",
    "    1. **Access and read the full content** of the research article from the provided URL\n",
    "    2. **Extract and analyze** all sections of the paper thoroughly\n",
    "    3. **Identify and highlight** Bold and increase size of Headings\n",
    "    4. **Provide a comprehensive summary** that includes:\n",
    "\n",
    "    - **Title and Authors**: The complete title and list of authors\n",
    "    - **Publication Details**: Journal name, publication date, DOI (if available)\n",
    "    - **Abstract Summary**: A concise overview of the abstract in your own words\n",
    "    - **Introduction/Background**: The research problem, context, and motivation for the study\n",
    "    - **Research Objectives**: The specific aims, hypotheses, or research questions\n",
    "    - **Methodology**: \n",
    "        - Study design and approach\n",
    "        - Sample size and participants (if applicable)\n",
    "        - Data collection methods\n",
    "        - Analysis techniques and tools used\n",
    "    - **Key Findings/Results**: \n",
    "        - Main outcomes and discoveries\n",
    "        - Statistical significance (if mentioned)\n",
    "        - Data patterns and trends\n",
    "    - **Discussion**: Interpretation of results and their implications\n",
    "    - **Limitations**: Any constraints or weaknesses acknowledged by the authors\n",
    "    - **Conclusions**: Final takeaways and the authors' main conclusions\n",
    "    - **Future Directions**: Suggestions for future research (if mentioned)\n",
    "    - **Significance**: Why this research matters to the field\n",
    "\n",
    "    4. **Structure your summary** in a clear, organized format with appropriate headings and subheadings\n",
    "    5. **Maintain academic accuracy** while making the content accessible and easy to understand\n",
    "    6. If you cannot access the full text, clearly state what portions you were able to read and summarize accordingly\n",
    "\n",
    "    Please provide the summary in a structured format that allows me to quickly grasp the essence of the research while also having\n",
    "    access to detailed information about each component of the study.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_user_prompt(self):\n",
    "        user_prompt = f\"\"\"\n",
    "            You are looking at a Article called: {self.Article}\n",
    "            Here are the contents page of given article \n",
    "            use this information to build a summary of the article in markdown without code blocks.\\n\\n\n",
    "            \"\"\"\n",
    "        user_prompt += self.fetch_page_and_all_relevant_links(self.url)\n",
    "        user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "        return user_prompt\n",
    "        \n",
    "\n",
    "    def stream_article(self):\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.summarizer_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": self.get_user_prompt()}\n",
    "            ],\n",
    "            stream=True\n",
    "        )    \n",
    "        response = \"\" \n",
    "        display_handle = display(Markdown(\"\"), display_id=True) \n",
    "        for chunk in stream: \n",
    "            response += chunk.choices[0].delta.content or '' \n",
    "            update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed91e359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## **Deep Residual Learning for Image Recognition** — Summary\n",
       "\n",
       "### **Authors**\n",
       "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
       "\n",
       "### **Publication Details**\n",
       "- Source: arXiv preprint 1512.03385 (2015). \n",
       "- Conference: Presented at CVPR 2016.\n",
       "- DOI: Not provided for the arXiv version; the conference proceedings contain the formal citation.\n",
       "\n",
       "---\n",
       "\n",
       "## **Abstract Summary**\n",
       "The paper introduces the idea of residual learning to tackle optimization difficulties in very deep neural networks. Rather than mapping an input x to a desired output H(x) directly, the network learns a residual function F(x) = H(x) − x, so that H(x) = F(x) + x. This simple reformulation, combined with shortcut connections that skip one or more layers, enables much deeper networks to be trained effectively. The authors propose residual blocks with identity shortcuts (and projection shortcuts when dimensions change) and demonstrate that networks with depths up to 152 layers outperform previous architectures on ImageNet and related benchmarks. They also introduce bottleneck blocks to build deeper networks efficiently. Overall, residual learning makes very deep CNNs practical and beneficial for image recognition.\n",
       "\n",
       "---\n",
       "\n",
       "## **Introduction / Background**\n",
       "- Deep CNNs historically suffer from optimization difficulties as depth increases (the so-called degradation problem: accuracy degrades with deeper architectures, even when more parameters are available).\n",
       "- Residual learning reframes the problem: instead of learning H(x) directly, the network learns F(x) that models the residual between the input and the target mapping, making it easier to optimize.\n",
       "- Skip connections (identity mappings) provide a direct path for gradients and information to flow through the network, mitigating vanishing/exploding gradient issues.\n",
       "- This framework enables systematic construction of very deep networks with improved trainability and generalization.\n",
       "\n",
       "---\n",
       "\n",
       "## **Research Objectives**\n",
       "- Develop a general residual learning framework that enables training of extremely deep networks (up to 152 layers) for image recognition.\n",
       "- Evaluate the benefits of residual connections across architectures of varying depth (e.g., 34, 50, 101, 152 layers).\n",
       "- Investigate design choices: identity vs projection shortcuts, bottleneck blocks, and their impact on performance and efficiency.\n",
       "- Demonstrate strong performance on large-scale (ImageNet) and smaller-scale (CIFAR) datasets.\n",
       "\n",
       "---\n",
       "\n",
       "## **Methodology**\n",
       "\n",
       "### Study Design and Approach\n",
       "- Architectural blueprint: Residual blocks composed of convolutional layers with skip connections that add input x to the block’s output F(x).\n",
       "- Block types:\n",
       "  - Basic block (used in shallower nets): typically two 3x3 convolutions with an identity skip.\n",
       "  - Bottleneck block (used for deeper nets): 1x1, 3x3, 1x1 convolutions to reduce and then restore dimensionality, enabling very deep networks with fewer parameters.\n",
       "- Shortcuts:\n",
       "  - Identity shortcuts when input and output dimensions match.\n",
       "  - Projection shortcuts (via 1x1 convolution) when downsampling or changing dimensionality is needed.\n",
       "- Training setup:\n",
       "  - Large-scale ImageNet dataset (1000-class classification) with data augmentation (random crops, horizontal flips, etc.).\n",
       "  - Convolutional layers followed by batch normalization and ReLU activations.\n",
       "  - Global average pooling before the final fully connected classifier.\n",
       "  - Stochastic gradient descent with momentum, weight decay, and carefully tuned learning rate schedules.\n",
       "- Evaluation:\n",
       "  - Comparisons across depths (e.g., 34-layer, 50-layer, 101-layer, 152-layer) on ImageNet.\n",
       "  - Additional validation on CIFAR datasets to illustrate generality.\n",
       "\n",
       "### Participants / Datasets\n",
       "- ImageNet (large-scale, 1000-class) used to benchmark performance of varying depths.\n",
       "- CIFAR-10 and CIFAR-100 used to further validate the residual approach on smaller images and datasets.\n",
       "\n",
       "### Data Collection Methods and Analysis Tools\n",
       "- Standard supervised training on GPUs with well-established deep learning toolchains.\n",
       "- Analysis centered on accuracy metrics (top-1 / top-5) and training convergence behavior across depths.\n",
       "\n",
       "---\n",
       "\n",
       "## **Key Findings / Results**\n",
       "\n",
       "### Main Outcomes\n",
       "- Residual learning enables effective training of very deep networks (up to 152 layers) that outperform their shallower counterparts and traditional deep CNNs.\n",
       "- Deeper ResNets consistently deliver better accuracy than shallower models, demonstrating that the degradation issue is mitigated by residual connections.\n",
       "- Bottleneck design enables deep architectures with more layers without an inordinate increase in parameters or computational cost.\n",
       "\n",
       "### Statistical Significance / Data Patterns\n",
       "- Deeper residual networks show marked improvements in accuracy on ImageNet relative to non-residual deep networks.\n",
       "- The 152-layer ResNet achieved state-of-the-art performance on ImageNet at the time, illustrating the practical benefits of extremely deep models.\n",
       "- Improvements were observed across both large-scale and smaller datasets, indicating the robustness of the residual framework.\n",
       "\n",
       "### Notable Architectural Insights\n",
       "- Identity shortcuts facilitate gradient flow and enable the network to learn residual functions that are easier to optimize.\n",
       "- When downsampling or changing dimensionality, projection shortcuts maintain information flow and alignment between layers.\n",
       "- The bottleneck block is particularly effective for very deep models, balancing depth with computational efficiency.\n",
       "\n",
       "---\n",
       "\n",
       "## **Discussion**\n",
       "\n",
       "- The introduction of residual connections fundamentally changes how very deep networks are optimized, making it feasible to train hundreds of layers without performance collapse.\n",
       "- Residual learning shifts the optimization target from fitting entire mappings to fitting residuals, which are typically easier to learn when the desired function is close to the identity.\n",
       "- The approach generalizes beyond ImageNet, benefiting various vision tasks and datasets, and has influenced a wide array of subsequent architectures.\n",
       "\n",
       "---\n",
       "\n",
       "## **Limitations**\n",
       "\n",
       "- Computational and memory demands grow with depth, posing practical constraints for training extremely deep models on limited hardware.\n",
       "- While residual connections alleviate optimization problems, the gains may exhibit diminishing returns beyond a certain depth or with suboptimal training setups.\n",
       "- The effectiveness of residual blocks is demonstrated on standard benchmarks; applicability to other domains or non-visual tasks may require adaptations.\n",
       "\n",
       "---\n",
       "\n",
       "## **Conclusions**\n",
       "\n",
       "- Deep residual learning makes extremely deep convolutional networks trainable and beneficial for image recognition.\n",
       "- The residual framework, especially with identity and projection shortcuts and bottleneck blocks, enables systematic construction of very deep nets that achieve state-of-the-art results.\n",
       "- This work has profoundly influenced subsequent deep learning research, establishing residual networks as a foundational architecture in computer vision and beyond.\n",
       "\n",
       "---\n",
       "\n",
       "## **Future Directions**\n",
       "\n",
       "- Exploration of even deeper or more efficient residual architectures, alternative shortcut designs, and improved bottleneck configurations.\n",
       "- Investigation into complementary techniques (e.g., normalization strategies, optimization tricks, data augmentation) to further improve training stability and performance.\n",
       "- Application of residual learning principles to other modalities and tasks (e.g., segmentation, detection, video, and non-vision domains).\n",
       "\n",
       "---\n",
       "\n",
       "## **Significance**\n",
       "\n",
       "- The paper introduced a simple yet powerful idea—residual connections—that dramatically improved the trainability and performance of very deep networks.\n",
       "- ResNets became a foundational architecture, enabling deeper models to reach or surpass prior performance ceilings and influencing a broad range of subsequent models, libraries, and practical applications in computer vision and beyond."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    summarizer = ArticleSummarizer(\n",
    "        Article=\"Deep Residual Learning for Image Recognition\",\n",
    "        url=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\"\n",
    "    )\n",
    "    summarizer.stream_article()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58d54f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
